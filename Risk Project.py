# -*- coding: utf-8 -*-
"""RiskProject

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SzojYMKWsSGM0D70d1W2TlBPY4ReHeRY
"""

import pandas as pd
import numpy as np
import yfinance as yf
from scipy.stats import norm, genpareto, probplot, skew, kurtosis
import matplotlib.pyplot as plt
import scipy.stats as stats
import cvxopt as opt
from cvxopt import blas, solvers
import seaborn as sns

tickers = ["IBM", "NVDA", "AMZN", "V", "AAPL", "JPM", "JNJ", "XOM"]
end_date='2024-12-06'
start_date ='2019-12-06'

data = yf.download(
    tickers=tickers,
    start=start_date,
    end=end_date,
    #period='5y',
    interval='1d',
    prepost=False
)['Adj Close']

returns = data.pct_change().dropna()
confidence_level = 0.95
alpha = 1 - confidence_level
z_score = norm.ppf(confidence_level)

# Calculate VaR at the specified confidence level
VaR_hist = returns.quantile(alpha, axis=0)
# Calculate Expected Shortfall (ES)
ES_hist = returns[returns <= VaR_hist].mean()
print("Value at Risk (VaR) at 95% confidence level:")
print(VaR_hist)
print("\nExpected Shortfall (ES):")
print(ES_hist)

# Variance-Covariance VaR
mean_returns = returns.mean()
std_devs = returns.std()       #
# Calculate VaR
VaR_varcov = - (mean_returns + z_score * std_devs)
# Expected Shortfall (ES) using Variance-Covariance method
ES_varcov = - mean_returns + (std_devs * norm.pdf(z_score) / (1 - confidence_level))
print("\nVariance-Covariance VaR at 95% confidence level:")
print(VaR_varcov)
print("\nVariance-Covariance Expected Shortfall (ES):")
print(-ES_varcov)

num_simulations = 10000
monte_carlo_results = {}
for ticker in tickers:
    historical_returns = returns[ticker]
    mean = historical_returns.mean()
    std = historical_returns.std()

    simulated_returns = np.random.normal(mean, std, num_simulations)

    VaR_mc = np.percentile(simulated_returns, (1 - confidence_level) * 100)

    ES_mc = simulated_returns[simulated_returns <= VaR_mc].mean()

    monte_carlo_results[ticker] = {
        "VaR (Monte Carlo)": VaR_mc,
        "ES (Monte Carlo)": ES_mc
    }
mc_results_df = pd.DataFrame(monte_carlo_results).T
print("\nMonte Carlo Simulation Results:")
print(mc_results_df)

##================================================================================================================================================================##

# Stressed Period Data
stressed_periods = {
    "2008 Financial Crisis": ("2008-09-01", "2009-03-31"),
    "COVID-19 Pandemic": ("2020-02-01", "2020-04-30")
}
VaR_stressed_hist = {}
ES_stressed_hist = {}
VaR_stressed_varcov = {}
ES_stressed_varcov = {}

for period_name, (start_date, end_date) in stressed_periods.items():
    data_stressed = yf.download(
        tickers=tickers,
        start=start_date,
        end=end_date,
        interval='1d',
        prepost=False
    )['Adj Close']

    data_stressed = data_stressed.dropna()
    returns_stressed = data_stressed.pct_change().dropna()

    # Historical VaR and ES using stressed period data
    VaR_stressed_hist[period_name] = returns_stressed.quantile(alpha, axis=0)
    ES_stressed_hist[period_name] = returns_stressed[returns_stressed <= VaR_stressed_hist[period_name]].mean()

    # Variance-Covariance VaR using stressed parameters
    mean_returns_stressed = returns_stressed.mean()
    std_devs_stressed = returns_stressed.std()
    VaR_stressed_varcov[period_name] = - (mean_returns_stressed + z_score * std_devs_stressed)
    ES_stressed_varcov[period_name] = - mean_returns_stressed + (std_devs_stressed * norm.pdf(z_score) / (1 - confidence_level))

for period_name in stressed_periods.keys():
    print(f"\n--- {period_name} ---")
    print("Historical VaR at 95% confidence level:")
    print(VaR_stressed_hist[period_name])
    print("\nHistorical Expected Shortfall (ES):")
    print(ES_stressed_hist[period_name])
    print("\nVariance-Covariance VaR at 95% confidence level:")
    print(VaR_stressed_varcov[period_name])
    print("\nVariance-Covariance Expected Shortfall (ES):")
    print(ES_stressed_varcov[period_name])

##================================================================================================================================================================##


# Calculate mean returns and covariance matrix
mean_returns = returns.mean()
cov_matrix = returns.cov()
risk_free_rate = 0.04 / 365

# Portfolio optimization functions
def minimum_variance_portfolio(mean_returns, cov_matrix):
    n = len(mean_returns)
    S = opt.matrix(cov_matrix.values)
    G = None
    h = None
    A = opt.matrix(1.0, (1, n))
    b = opt.matrix(1.0)

    solvers.options['show_progress'] = False
    min_vol_solution = solvers.qp(S, opt.matrix(0.0, (n, 1)), G, h, A, b)
    min_vol_weights = np.array(min_vol_solution['x']).flatten()

    return min_vol_weights

min_vol_weights = minimum_variance_portfolio(mean_returns, cov_matrix)
print("\nMinimum Volatility Portfolio Weights:")
print(pd.Series(min_vol_weights, index=mean_returns.index))

# Calculate portfolio performance
def portfolio_performance(weights, mean_returns, cov_matrix, risk_free_rate):
    portfolio_return = np.dot(weights, mean_returns)
    portfolio_std_dev = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
    sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_std_dev
    return portfolio_return, portfolio_std_dev, sharpe_ratio

min_vol_perf = portfolio_performance(min_vol_weights, mean_returns, cov_matrix, risk_free_rate)
print("\nMinimum Volatility Portfolio Performance (Return, Volatility, Sharpe):")
print(min_vol_perf)
print("\nOptimized portfolio weights:")
print(min_vol_weights)

def expected_shortfall_optimization(returns, confidence_level=0.95):
    n = returns.shape[1]
    T = returns.shape[0]
    alpha = 1 - confidence_level

    total_vars = n + 1 + T

    c = np.zeros(total_vars)
    c[n] = 1
    c[n+1:] = 1 / (alpha * T)
    c = opt.matrix(c)
    G = np.zeros((T, total_vars))
    G[:, :n] = -returns.values
    G[:, n] = -1
    G[:, n+1:] = -np.eye(T)
    G = opt.matrix(G)
    h = opt.matrix(np.zeros(T))
    G_s = np.zeros((T, total_vars))
    G_s[:, n+1:] = -np.eye(T)  # -s_i <= 0
    G_s = opt.matrix(G_s)
    h_s = opt.matrix(np.zeros(T))
    G = opt.matrix(np.vstack([G, G_s]))
    h = opt.matrix(np.vstack([h, h_s]))
    A = np.zeros((1, total_vars))
    A[0, :n] = 1
    A = opt.matrix(A)
    b = opt.matrix(1.0)

    # Solve optimization problem
    solvers.options['show_progress'] = False
    solution = solvers.lp(c, G, h, A, b)
    weights = np.array(solution['x'][:n]).flatten()

    return weights

# Optimize portfolio to minimize Expected Shortfall
es_weights = expected_shortfall_optimization(returns, confidence_level)
print("\nExpected Shortfall Minimization Portfolio Weights:")
print(pd.Series(es_weights, index=mean_returns.index))

# Calculate performance of ES optimized portfolio
es_portfolio_perf = portfolio_performance(es_weights, mean_returns, cov_matrix, risk_free_rate)
print("\nExpected Shortfall Minimization Portfolio Performance (Return, Volatility, Sharpe):")
print(es_portfolio_perf)

##================================================================================================================================================================##

# Calculate skewness and kurtosis
skewness = returns.skew()
kurt = returns.kurtosis()

print("\nSkewness:\n", skewness)
print("\nKurtosis:\n", kurt)

# Calculate portfolio returns
portfolio_returns = returns.dot(min_vol_weights)

# Portfolio-level VaR
VaR_portfolio = portfolio_returns.quantile(alpha)

# Plot portfolio return distribution with VaR
sns.histplot(portfolio_returns, kde=True, bins=50, color='blue')
plt.axvline(VaR_portfolio, color='red', linestyle='dashed', linewidth=2, label='VaR')
plt.title("Minimum Variance Portfolio Return Distribution with VaR")
plt.legend()
plt.show()

# ES optimized portfolio returns
es_portfolio_returns = returns.dot(es_weights)

# Portfolio-level VaR for ES optimized portfolio
VaR_es_portfolio = es_portfolio_returns.quantile(alpha)

# Plot ES optimized portfolio return distribution with VaR
sns.histplot(es_portfolio_returns, kde=True, bins=50, color='green')
plt.axvline(VaR_es_portfolio, color='red', linestyle='dashed', linewidth=2, label='VaR')
plt.title("ES Optimized Portfolio Return Distribution with VaR")
plt.legend()
plt.show()

# Tail ratio calculation per ticker
top_5 = returns.apply(lambda x: x[x >= x.quantile(0.95)].mean())
bottom_5 = returns.apply(lambda x: x[x <= x.quantile(0.05)].mean())
tail_ratio = top_5 / abs(bottom_5)
print("\nTail Ratio (Top 5% / Bottom 5%):")
print(tail_ratio)

returns_clean = returns.replace([np.inf, -np.inf], np.nan).dropna()

hill_estimators = {}
for ticker in returns_clean.columns:
    returns_ticker = returns_clean[ticker]
    threshold = returns_ticker.quantile(0.95)
    extreme_returns = returns_ticker[returns_ticker > threshold]

    if len(extreme_returns) > 1:
        sorted_extremes = np.sort(extreme_returns)[::-1]

        k = len(sorted_extremes) - 1
        dynamic_threshold = sorted_extremes[-1]
        hill_estimator = (1 / k) * sum(np.log(sorted_extremes[:-1] / dynamic_threshold))
        hill_estimators[ticker] = 1/hill_estimator
    else:
        hill_estimators[ticker] = np.nan

hill_estimators_series = pd.Series(hill_estimators)
print("\nHill Estimator for Tail Risk:\n", hill_estimators_series)

n_rows, n_cols = 4, 2
fig_normal, axes_normal = plt.subplots(n_rows, n_cols, figsize=(16, 16))
axes_normal = axes_normal.flatten()

fig_pareto, axes_pareto = plt.subplots(n_rows, n_cols, figsize=(16, 20))
axes_pareto = axes_pareto.flatten()
for i, ticker in enumerate(returns_clean.columns):
    ticker_returns = returns_clean[ticker]

    # Normal QQ Plot
    if len(ticker_returns) > 0:
        probplot(ticker_returns, dist="norm", plot=axes_normal[i])
        axes_normal[i].set_title(f"Normal QQ Plot for {ticker}")
        axes_normal[i].set_xlabel("Theoretical Quantiles")
        axes_normal[i].set_ylabel("Ordered Values")
    else:
        print(f"No data available to plot Normal QQ plot for {ticker}.")

    # Pareto QQ Plot
    threshold = ticker_returns.quantile(0.05)
    left_tail = ticker_returns[ticker_returns <= threshold]

    if not np.all(np.isfinite(left_tail)):
        print(f"Non-finite values detected in left-tail data for {ticker}.")
        left_tail = left_tail[np.isfinite(left_tail)]

    neg_left_tail = -left_tail.values.flatten()
    if len(neg_left_tail) > 0:
        params = genpareto.fit(neg_left_tail)
        shape, loc, scale = params
        theoretical_quantiles = genpareto.ppf(
            np.linspace(0.01, 0.99, len(neg_left_tail)), shape, loc=loc, scale=scale
        )
        sorted_empirical = np.sort(neg_left_tail)

        # Pareto QQ Plot
        axes_pareto[i].scatter(theoretical_quantiles, sorted_empirical, alpha=0.7, label="Empirical vs. Theoretical")
        axes_pareto[i].plot(theoretical_quantiles, theoretical_quantiles, color='red', linestyle='--', label="45-degree line")
        axes_pareto[i].set_title(f"Pareto QQ Plot for {ticker}")
        axes_pareto[i].set_xlabel("Theoretical Quantiles (Pareto)")
        axes_pareto[i].set_ylabel("Empirical Quantiles")
        axes_pareto[i].legend()
        axes_pareto[i].grid()
    else:
        print(f"Not enough data in the left tail for Pareto QQ plot for {ticker}.")

fig_normal.tight_layout()
plt.show()
fig_pareto.tight_layout()
plt.show()

##================================================================================================================================================================##

# Extreme Risk Analysis on an Optimized Portfolio
portfolio_returns = -returns.dot(min_vol_weights)

# Portfolio VaR and ES
VaR_portfolio_hist = portfolio_returns.quantile(alpha)
ES_portfolio_hist = portfolio_returns[portfolio_returns <= VaR_portfolio_hist].mean()

# Variance-Covariance VaR and ES for the Portfolio
portfolio_mean_return = portfolio_returns.mean()
portfolio_std_dev = portfolio_returns.std()
VaR_portfolio_varcov = -(portfolio_mean_return + z_score * portfolio_std_dev)
ES_portfolio_varcov = -(portfolio_mean_return + portfolio_std_dev * norm.pdf(z_score) / (1 - confidence_level))

# Monte Carlo VaR and ES for the Portfolio
simulated_portfolio_returns = np.random.normal(portfolio_mean_return, portfolio_std_dev, num_simulations)
VaR_portfolio_mc = np.percentile(simulated_portfolio_returns, (1 - confidence_level) * 100)
ES_portfolio_mc = simulated_portfolio_returns[simulated_portfolio_returns <= VaR_portfolio_mc].mean()

# Tail Statistics
portfolio_skewness = skew(portfolio_returns)
portfolio_kurtosis = kurtosis(portfolio_returns)

# Hill Estimator
portfolio_extreme_returns = portfolio_returns[portfolio_returns > portfolio_returns.quantile(0.95)]

if len(portfolio_extreme_returns) > 1:
    sorted_extremes = np.sort(portfolio_extreme_returns)[::-1]

    dynamic_threshold = sorted_extremes[-1]
    k = len(sorted_extremes) - 1
    hill_estimator_portfolio = 1/((1 / k) * sum(np.log(sorted_extremes[:-1] / dynamic_threshold)))
else:
    hill_estimator_portfolio = np.nan

portfolio_results = {
    "VaR_Historical": VaR_portfolio_hist,
    "ES_Historical": ES_portfolio_hist,
    "VaR_VarianceCovariance": VaR_portfolio_varcov,
    "ES_VarianceCovariance": ES_portfolio_varcov,
    "VaR_MonteCarlo": VaR_portfolio_mc,
    "ES_MonteCarlo": ES_portfolio_mc,
    "Skewness": portfolio_skewness,
    "Kurtosis": portfolio_kurtosis,
    "Hill_Estimator": hill_estimator_portfolio,
}

print("\nPortfolio-Level Extreme Risk Analysis Results:")
for key, value in portfolio_results.items():
    print(f"{key}: {value}")

##================================================================================================================================================================##

# Mean Excess Plot Function
def mean_excess_plot(data, quantiles=None):
    data = np.sort(data)

    if quantiles is None:
        quantiles = np.linspace(0.8, 0.99, 100)
    thresholds = np.quantile(data, quantiles)

    mean_excess_values = []
    for u in thresholds:
        exceedances = data[data > u] - u
        if len(exceedances) > 0:
            mean_excess_values.append(exceedances.mean())
        else:
            mean_excess_values.append(np.nan)

    plt.figure(figsize=(10, 6))
    plt.plot(thresholds, mean_excess_values, marker='o', linestyle='-', label="Mean Excess")
    plt.xlabel("Threshold (u)")
    plt.ylabel("Mean Excess (e(u))")
    plt.title("Mean Excess Plot")
    plt.grid(True)
    plt.legend()
    plt.show()

# GPD Shape Parameter vs. Threshold Plot
def gpd_shape_vs_threshold(data, quantiles=None):
    data = np.sort(data)

    if quantiles is None:
        quantiles = np.linspace(0.6, 0.99, 50)
    thresholds = np.quantile(data, quantiles)

    shape_parameters = []

    for u in thresholds:
        exceedances = data[data > u] - u
        if len(exceedances) > 0:
            params = genpareto.fit(-exceedances)
            shape, _, _ = params
            shape_parameters.append(shape)
        else:
            shape_parameters.append(np.nan)

    plt.figure(figsize=(10, 6))
    plt.plot(thresholds, shape_parameters, marker='o', linestyle='-', label="Shape Parameter (\u03BE)")
    plt.axhline(0, color='red', linestyle='--', label="Threshold for Light/Heavy Tails (\u03BE = 0)")
    plt.xlabel("Threshold (u)")
    plt.ylabel("Shape Parameter (\u03BE)")
    plt.title("Fitted GPD Shape Parameter vs. Threshold")
    plt.grid(True)
    plt.legend()
    plt.show()

mean_excess_plot(portfolio_returns)
gpd_shape_vs_threshold(portfolio_returns)



def pot_var_es(data, threshold, confidence_level):

    exceedances = data[data > threshold] - threshold

    if len(exceedances) == 0:
        raise ValueError("No exceedances above the threshold. Choose a lower threshold.")

    shape, loc, scale = genpareto.fit(exceedances, floc=0)

    num_exceedances = len(exceedances)
    total_data_points = len(data)
    probability_exceedance = num_exceedances / total_data_points

    adjusted_probability = (1 - confidence_level) / probability_exceedance
    VaR = threshold + (scale / shape) * ((adjusted_probability) ** (-shape) - 1)

    if shape < 1:
        ES = VaR + (scale - shape * (VaR - threshold)) / (1 - shape)
    else:
        ES = np.inf

    return VaR, ES


threshold = 0.016
confidence_level = 0.95

# Calculate VaR and ES using PoT
try:
    VaR_pot, ES_pot = pot_var_es(portfolio_returns, threshold, confidence_level)
    print(f"PoT VaR at {confidence_level * 100}% confidence: {VaR_pot}")
    print(f"PoT ES at {confidence_level * 100}% confidence: {ES_pot}")
except ValueError as e:
    print(e)



def fit_gpd_and_visualize(data, threshold):
    exceedances = data[data > threshold] - threshold

    if len(exceedances) == 0:
        raise ValueError("No exceedances above the threshold. Choose a lower threshold.")

    shape, loc, scale = genpareto.fit(exceedances, floc=0)
    params = (shape, loc, scale)
    print(f"Fitted GPD Parameters: Shape={shape}, Location={loc}, Scale={scale}")

    theoretical_quantiles = genpareto.ppf(
        np.linspace(0.01, 0.99, len(exceedances)), shape, loc=loc, scale=scale
    )
    empirical_quantiles = np.sort(exceedances)

    plt.figure(figsize=(8, 6))
    plt.scatter(theoretical_quantiles, empirical_quantiles, alpha=0.7, label="Empirical vs. Theoretical")
    plt.plot(theoretical_quantiles, theoretical_quantiles, color='red', linestyle='--', label="45-degree line")
    plt.title("Q-Q Plot for Fitted GPD")
    plt.xlabel("Theoretical Quantiles (GPD)")
    plt.ylabel("Empirical Quantiles")
    plt.legend()
    plt.grid()
    plt.show()

    sorted_exceedances = np.sort(exceedances)
    ecdf = np.arange(1, len(sorted_exceedances) + 1) / len(sorted_exceedances)  # Empirical CDF
    fitted_cdf = genpareto.cdf(sorted_exceedances, shape, loc=loc, scale=scale)  # Fitted GPD CDF

    plt.figure(figsize=(8, 6))
    plt.step(sorted_exceedances, ecdf, where='post', label="Empirical CDF", color="blue")
    plt.plot(sorted_exceedances, fitted_cdf, label="Fitted GPD CDF", color="red", linestyle="--")
    plt.title("Empirical CDF vs. Fitted GPD CDF")
    plt.xlabel("Exceedances")
    plt.ylabel("CDF")
    plt.legend()
    plt.grid()
    plt.show()

    return params

threshold = 0.016
params = fit_gpd_and_visualize(portfolio_returns, threshold)